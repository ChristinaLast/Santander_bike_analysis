{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Santander Cycling data (Random forest) to predict bike occupancy for December.\n",
    "https://cycling.data.tfl.gov.uk/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "from xml.etree import ElementTree as ET\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "from pandas.io.json import json_normalize\n",
    "from itertools import chain, starmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data_2012_zip = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2012.zip\")\n",
    "bike_data_2013_zip = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2013.zip\")\n",
    "bike_data_2014_zip = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/cyclehireusagestats-2014.zip\")\n",
    "bike_data_2015_zip = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/2015TripDatazip.zip\")\n",
    "bike_data_2016_zip = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/2016TripDataZip.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import zipfile\n",
    "def encoding_zipfile(url):    \n",
    "    with ZipFile(BytesIO(url.read())) as zipfile:\n",
    "        for fileinfo in zipfile.infolist():\n",
    "            filename = fileinfo.filename.encode('cp437').decode('gbk')\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Journey Data Extract 01Jan-05Jan13.csv\n",
      "10. Journey Data Extract 18Aug-13Sep13.csv\n",
      "11. Journey Data Extract 14Sep13-12Oct13.csv\n",
      "12. Journey Data Extract 13Oct13-09Nov13.csv\n",
      "13. Journey Data Extract 10Nov13-07Dec13.csv\n",
      "14. Journey Data Extract 08Dec13-04Jan14.csv\n",
      "2. Journey Data Extract 06Jan-02Feb13.csv\n",
      "3. Journey Data Extract 03Feb-02Mar13.csv\n",
      "4. Journey Data Extract 03Mar-31Mar13.csv\n",
      "5. Journey Data Extract 01Apr-27Apr13.csv\n",
      "6. Journey Data Extract 28Apr-25May13.csv\n",
      "7. Journey Data Extract 26May-22Jun13.csv\n",
      "8. Journey Data Extract 23Jun-20Jul13.csv\n",
      "9. Journey Data Extract 21Jul-17Aug13.csv\n"
     ]
    }
   ],
   "source": [
    "bike_data_2013 = encoding_zipfile(bike_data_2013_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def unicode_csv_reader(utf8_data, dialect=csv.excel, **kwargs):\n",
    "    csv_reader = csv.reader(utf8_data, dialect=dialect, **kwargs)\n",
    "    for row in csv_reader:\n",
    "        yield [unicode(cell, 'utf-8') for cell in row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to parse zipfiles to dataframe\n",
    "def zipfile_to_df(url):    \n",
    "    with ZipFile(BytesIO(url.read())) as zipfile:\n",
    "        dfs = []\n",
    "        for col_name in zipfile.namelist():\n",
    "            with zipfile.open(col_name) as csv:\n",
    "                df = pd.read_csv(csv, index_col=None, header=0)\n",
    "                dfs.append(df)\n",
    "    data = pd.concat(dfs, ignore_index=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/bike_data_analysis/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3242: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/Users/admin/bike_data_analysis/lib/python3.7/site-packages/ipykernel_launcher.py:9: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Applying read function to 2015 and 2016 bike data\n",
    "bike_2012_df = zipfile_to_df(bike_data_2012_zip)\n",
    "#bike_2013_df = zipfile_to_df(bike_data_2013_zip)\n",
    "#bike_2014_df = zipfile_to_df(bike_data_2014_zip)\n",
    "bike_2015_df = zipfile_to_df(bike_data_2015_zip)\n",
    "bike_2016_df = zipfile_to_df(bike_data_2016_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning incorrect results on 2012 dataframe\n",
    "bike_2012_df = bike_2012_df[bike_2012_df['StartStation Id'] != 'Tabletop1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/bike_data_analysis/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Concatenating all dataframes that can be read in cleanly\n",
    "bike_data = pd.concat([bike_2012_df,bike_2015_df,bike_2016_df], ignore_index=True).drop(['Unnamed: 10', 'Unnamed: 11', 'Unnamed: 9','EndStation Logical Terminal','StartStation Logical Terminal','endStationPriority_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bike_data(dataframe):\n",
    "    print(\"Original shape: \",dataframe.shape)\n",
    "    dataframe.dropna(axis=0, subset=[\"StartStation Id\", \"EndStation Id\", \"Start Date\", \"End Date\"], inplace=True)\n",
    "    print(\"Shape after dropping Na results: \",dataframe.shape)\n",
    "    \n",
    "    dataframe[\"EndStation Id\"] = dataframe[\"EndStation Id\"].astype(int)\n",
    "    dataframe[\"StartStation Id\"] = dataframe[\"StartStation Id\"].astype(int)\n",
    "    \n",
    "    dataframe = dataframe[dataframe[\"StartStation Id\"] != dataframe[\"EndStation Id\"]]\n",
    "    dataframe = dataframe.loc[:,('Start Date',\n",
    "                           'StartStation Id',\n",
    "                           'End Date',\n",
    "                           'EndStation Id',\n",
    "                           'Duration')]                 \n",
    "    print(\"Shape after removing trips which start and end at the same location\", dataframe.shape)\n",
    "    ## Extra drop for duplicates\n",
    "    dataframe.drop_duplicates(inplace=True)\n",
    "    print(\"Shape after removing duplicates: \",dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape:  (29267602, 9)\n",
      "Shape after dropping Na results:  (28933309, 9)\n",
      "Shape after removing trips which start and end at the same location (27917787, 5)\n",
      "Shape after removing duplicates:  (26858182, 5)\n"
     ]
    }
   ],
   "source": [
    "clean_bike_data(bike_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_locations = \"https://tfl.gov.uk/tfl/syndication/feeds/cycle-hire/livecyclehireupdates.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url containing the locations of all Santander bike stops\n",
    "bike_locations = \"https://tfl.gov.uk/tfl/syndication/feeds/cycle-hire/livecyclehireupdates.xml\"\n",
    "\n",
    "def get_location_from_xml(url):\n",
    "    response = requests.get(url)\n",
    "    root = ET.fromstring(response.content)\n",
    "    \n",
    "    col_list = []\n",
    "    for i in range(0, len(root)):\n",
    "        id_list = int(root[i][0].text)\n",
    "        name_list = str(root[i][1].text)\n",
    "        lat_list = float(root[i][3].text)\n",
    "        lon_list = float(root[i][4].text)\n",
    "        capacity_list = int(root[i][12].text)\n",
    "        col_list.append([id_list,name_list,lat_list,lon_list,capacity_list])\n",
    "    \n",
    "    all_locs = pd.DataFrame(list(col_list), columns = [\"name\",\"id\",\"lat\",\"lon\",\"capacity\"])\n",
    "#    all_locs.to_dataframe(url.split('/')[7].split('.')[0]+'.csv', header=True, index=None)\n",
    "    print(\"Shape of cycle hire locations: \",all_locs.shape)\n",
    "    \n",
    "    return all_locs\n",
    "\n",
    "bike_locations = get_location_from_xml(bike_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>04/01/2012 00:20</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Porchester Place: Paddington</td>\n",
       "      <td>9340768</td>\n",
       "      <td>04/01/2012 00:00</td>\n",
       "      <td>224</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>224</td>\n",
       "      <td>51.51031</td>\n",
       "      <td>-0.187402</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6603.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>04/01/2012 07:37</td>\n",
       "      <td>224.0</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>9363259</td>\n",
       "      <td>04/01/2012 07:37</td>\n",
       "      <td>224</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>224</td>\n",
       "      <td>51.51031</td>\n",
       "      <td>-0.187402</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3992.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>04/01/2012 07:39</td>\n",
       "      <td>176.0</td>\n",
       "      <td>Gloucester Terrace: Bayswater</td>\n",
       "      <td>9355931</td>\n",
       "      <td>04/01/2012 07:37</td>\n",
       "      <td>224</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>224</td>\n",
       "      <td>51.51031</td>\n",
       "      <td>-0.187402</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2699.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>04/01/2012 08:16</td>\n",
       "      <td>224.0</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>9357327</td>\n",
       "      <td>04/01/2012 08:10</td>\n",
       "      <td>224</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>224</td>\n",
       "      <td>51.51031</td>\n",
       "      <td>-0.187402</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6603.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>04/01/2012 08:26</td>\n",
       "      <td>428.0</td>\n",
       "      <td>Exhibition Road: Knightsbridge</td>\n",
       "      <td>9360881</td>\n",
       "      <td>04/01/2012 08:14</td>\n",
       "      <td>224</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>224</td>\n",
       "      <td>51.51031</td>\n",
       "      <td>-0.187402</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bike Id  Duration          End Date  EndStation Id  \\\n",
       "0    893.0    1238.0  04/01/2012 00:20          169.0   \n",
       "1   6603.0      19.0  04/01/2012 07:37          224.0   \n",
       "2   3992.0     111.0  04/01/2012 07:39          176.0   \n",
       "3   2699.0     373.0  04/01/2012 08:16          224.0   \n",
       "4   6603.0     707.0  04/01/2012 08:26          428.0   \n",
       "\n",
       "                  EndStation Name  Rental Id        Start Date  \\\n",
       "0    Porchester Place: Paddington    9340768  04/01/2012 00:00   \n",
       "1           Whiteley's: Bayswater    9363259  04/01/2012 07:37   \n",
       "2   Gloucester Terrace: Bayswater    9355931  04/01/2012 07:37   \n",
       "3           Whiteley's: Bayswater    9357327  04/01/2012 08:10   \n",
       "4  Exhibition Road: Knightsbridge    9360881  04/01/2012 08:14   \n",
       "\n",
       "  StartStation Id      StartStation Name  name       lat       lon  capacity  \n",
       "0             224  Whiteley's: Bayswater   224  51.51031 -0.187402        17  \n",
       "1             224  Whiteley's: Bayswater   224  51.51031 -0.187402        17  \n",
       "2             224  Whiteley's: Bayswater   224  51.51031 -0.187402        17  \n",
       "3             224  Whiteley's: Bayswater   224  51.51031 -0.187402        17  \n",
       "4             224  Whiteley's: Bayswater   224  51.51031 -0.187402        17  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data_locations = bike_data.merge(bike_locations, left_on=['StartStation Id'], right_on=['name'], suffixes=('_s')).drop(columns='id')\n",
    "bike_data_locations.rename(columns={\"name\": \"sname\", \n",
    "                                    \"lat\": \"slat\",\n",
    "                                    \"lon\": \"slon\",\n",
    "                                    \"capacity\": \"scap\"\n",
    "                                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data_locations.merge(bike_data_locations, left_on=['EndStation Id'], right_on=['name'], suffixes=('_e')).drop(columns='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>capacity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893.0</td>\n",
       "      <td>1238.0</td>\n",
       "      <td>04/01/2012 00:20</td>\n",
       "      <td>169</td>\n",
       "      <td>Porchester Place: Paddington</td>\n",
       "      <td>9340768</td>\n",
       "      <td>04/01/2012 00:00</td>\n",
       "      <td>224</td>\n",
       "      <td>Whiteley's: Bayswater</td>\n",
       "      <td>169</td>\n",
       "      <td>51.514746</td>\n",
       "      <td>-0.165164</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4780.0</td>\n",
       "      <td>792.0</td>\n",
       "      <td>04/01/2012 07:35</td>\n",
       "      <td>169</td>\n",
       "      <td>Porchester Place: Paddington</td>\n",
       "      <td>9352469</td>\n",
       "      <td>04/01/2012 07:21</td>\n",
       "      <td>16</td>\n",
       "      <td>Cartwright Gardens : Bloomsbury</td>\n",
       "      <td>169</td>\n",
       "      <td>51.514746</td>\n",
       "      <td>-0.165164</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4999.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>04/01/2012 08:23</td>\n",
       "      <td>169</td>\n",
       "      <td>Porchester Place: Paddington</td>\n",
       "      <td>9355146</td>\n",
       "      <td>04/01/2012 08:06</td>\n",
       "      <td>64</td>\n",
       "      <td>William IV Street: Strand</td>\n",
       "      <td>169</td>\n",
       "      <td>51.514746</td>\n",
       "      <td>-0.165164</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3632.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>04/01/2012 08:35</td>\n",
       "      <td>169</td>\n",
       "      <td>Porchester Place: Paddington</td>\n",
       "      <td>9358584</td>\n",
       "      <td>04/01/2012 08:16</td>\n",
       "      <td>229</td>\n",
       "      <td>Whitehall Place: Strand</td>\n",
       "      <td>169</td>\n",
       "      <td>51.514746</td>\n",
       "      <td>-0.165164</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2332.0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>04/01/2012 09:00</td>\n",
       "      <td>169</td>\n",
       "      <td>Porchester Place: Paddington</td>\n",
       "      <td>9356030</td>\n",
       "      <td>04/01/2012 08:37</td>\n",
       "      <td>113</td>\n",
       "      <td>Gloucester Road (Central): South Kensington</td>\n",
       "      <td>169</td>\n",
       "      <td>51.514746</td>\n",
       "      <td>-0.165164</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bike Id  Duration          End Date  EndStation Id  \\\n",
       "0    893.0    1238.0  04/01/2012 00:20            169   \n",
       "1   4780.0     792.0  04/01/2012 07:35            169   \n",
       "2   4999.0    1024.0  04/01/2012 08:23            169   \n",
       "3   3632.0    1120.0  04/01/2012 08:35            169   \n",
       "4   2332.0    1416.0  04/01/2012 09:00            169   \n",
       "\n",
       "                EndStation Name  Rental Id        Start Date  StartStation Id  \\\n",
       "0  Porchester Place: Paddington    9340768  04/01/2012 00:00              224   \n",
       "1  Porchester Place: Paddington    9352469  04/01/2012 07:21               16   \n",
       "2  Porchester Place: Paddington    9355146  04/01/2012 08:06               64   \n",
       "3  Porchester Place: Paddington    9358584  04/01/2012 08:16              229   \n",
       "4  Porchester Place: Paddington    9356030  04/01/2012 08:37              113   \n",
       "\n",
       "                             StartStation Name  name        lat       lon  \\\n",
       "0                        Whiteley's: Bayswater   169  51.514746 -0.165164   \n",
       "1              Cartwright Gardens : Bloomsbury   169  51.514746 -0.165164   \n",
       "2                    William IV Street: Strand   169  51.514746 -0.165164   \n",
       "3                      Whitehall Place: Strand   169  51.514746 -0.165164   \n",
       "4  Gloucester Road (Central): South Kensington   169  51.514746 -0.165164   \n",
       "\n",
       "   capacity  \n",
       "0        18  \n",
       "1        18  \n",
       "2        18  \n",
       "3        18  \n",
       "4        18  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate list of unique routes\n",
    "unq_locs = all_data.loc[:,('StartStation Id',\n",
    "                      'EndStation Id')]\n",
    "print(unq_locs.shape)\n",
    "unq_locs.drop_duplicates(inplace=True)\n",
    "print(unq_locs.shape)\n",
    "\n",
    "## Merge on the lat/lons\n",
    "\n",
    "unq_locs = unq_locs.merge(right = all_locs,\n",
    "                             how = 'inner',\n",
    "                             left_on = 'StartStation Id',\n",
    "                             right_on = 'id')\n",
    "\n",
    "print(unq_locs.shape)\n",
    "\n",
    "unq_locs.drop(labels = [\"id\", \"name\"], axis=1, inplace=True)\n",
    "unq_locs.rename(columns={'lat': 'StartStation lat', 'lon': 'StartStation lon', \n",
    "                            'capacity': 'StartStation capacity'},\n",
    "                   inplace=True)\n",
    "# Merge end\n",
    "unq_locs = unq_locs.merge(right = all_locs,\n",
    "                             how = 'inner',\n",
    "                             left_on = 'EndStation Id',\n",
    "                             right_on = 'id')\n",
    "\n",
    "unq_locs.drop(labels = [\"id\", \"name\"], axis=1, inplace=True)\n",
    "unq_locs.rename(columns={'lat': 'EndStation lat', 'lon': 'EndStation lon',\n",
    "                           'capacity': 'EndStation capacity'},\n",
    "                   inplace=True)\n",
    "\n",
    "\n",
    "print(unq_locs.shape)\n",
    "unq_locs.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
