{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Santander Cycling data (Random forest) to predict bike occupancy for December.\n",
    "https://cycling.data.tfl.gov.uk/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "    \n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading to dataframe from static url for .csv file\n",
    "test_url=\"https://cycling.data.tfl.gov.uk/usage-stats/01aJourneyDataExtract10Jan16-23Jan16.csv\"\n",
    "test_request=requests.get(test_url).content\n",
    "test_decode=pd.read_csv(io.StringIO(test_request.decode('utf-8')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rental Id</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Bike Id</th>\n",
       "      <th>End Date</th>\n",
       "      <th>EndStation Id</th>\n",
       "      <th>EndStation Name</th>\n",
       "      <th>Start Date</th>\n",
       "      <th>StartStation Id</th>\n",
       "      <th>StartStation Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50754225</td>\n",
       "      <td>240</td>\n",
       "      <td>11834</td>\n",
       "      <td>10/01/2016 00:04</td>\n",
       "      <td>383.0</td>\n",
       "      <td>Frith Street, Soho</td>\n",
       "      <td>10/01/2016 00:00</td>\n",
       "      <td>18</td>\n",
       "      <td>Drury Lane, Covent Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50754226</td>\n",
       "      <td>300</td>\n",
       "      <td>9648</td>\n",
       "      <td>10/01/2016 00:05</td>\n",
       "      <td>719.0</td>\n",
       "      <td>Victoria Park Road, Hackney Central</td>\n",
       "      <td>10/01/2016 00:00</td>\n",
       "      <td>479</td>\n",
       "      <td>Pott Street, Bethnal Green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50754227</td>\n",
       "      <td>1200</td>\n",
       "      <td>10689</td>\n",
       "      <td>10/01/2016 00:20</td>\n",
       "      <td>272.0</td>\n",
       "      <td>Baylis Road, Waterloo</td>\n",
       "      <td>10/01/2016 00:00</td>\n",
       "      <td>425</td>\n",
       "      <td>Harrington Square 2, Camden Town</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50754228</td>\n",
       "      <td>780</td>\n",
       "      <td>8593</td>\n",
       "      <td>10/01/2016 00:14</td>\n",
       "      <td>471.0</td>\n",
       "      <td>Hewison Street, Old Ford</td>\n",
       "      <td>10/01/2016 00:01</td>\n",
       "      <td>487</td>\n",
       "      <td>Canton Street, Poplar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50754229</td>\n",
       "      <td>600</td>\n",
       "      <td>8619</td>\n",
       "      <td>10/01/2016 00:11</td>\n",
       "      <td>399.0</td>\n",
       "      <td>Brick Lane Market, Shoreditch</td>\n",
       "      <td>10/01/2016 00:01</td>\n",
       "      <td>501</td>\n",
       "      <td>Cephas Street, Bethnal Green</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rental Id  Duration  Bike Id          End Date  EndStation Id  \\\n",
       "0   50754225       240    11834  10/01/2016 00:04          383.0   \n",
       "1   50754226       300     9648  10/01/2016 00:05          719.0   \n",
       "2   50754227      1200    10689  10/01/2016 00:20          272.0   \n",
       "3   50754228       780     8593  10/01/2016 00:14          471.0   \n",
       "4   50754229       600     8619  10/01/2016 00:11          399.0   \n",
       "\n",
       "                       EndStation Name        Start Date  StartStation Id  \\\n",
       "0                   Frith Street, Soho  10/01/2016 00:00               18   \n",
       "1  Victoria Park Road, Hackney Central  10/01/2016 00:00              479   \n",
       "2                Baylis Road, Waterloo  10/01/2016 00:00              425   \n",
       "3             Hewison Street, Old Ford  10/01/2016 00:01              487   \n",
       "4        Brick Lane Market, Shoreditch  10/01/2016 00:01              501   \n",
       "\n",
       "                  StartStation Name  \n",
       "0         Drury Lane, Covent Garden  \n",
       "1        Pott Street, Bethnal Green  \n",
       "2  Harrington Square 2, Camden Town  \n",
       "3             Canton Street, Poplar  \n",
       "4      Cephas Street, Bethnal Green  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_decode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading zipfile url and passing all the titles of csv's to a list\n",
    "test_response = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/2015TripDatazip.zip\")\n",
    "test_zipfile = ZipFile(BytesIO(test_response.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_zipfile.namelist()\n",
    "print(test_zipfile.namelist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipfile_to_df():\n",
    "    \n",
    "    test_response = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/2015TripDatazip.zip\")\n",
    "    \n",
    "    iter_csv_dict_2015 = { v:k for k,v in csv_dict_2015.items()}\n",
    "\n",
    "    with ZipFile(BytesIO(test_response.read())) as test_zipfile:\n",
    "        \n",
    "        all_dfs = []\n",
    "        for test_name in test_zipfile.namelist():\n",
    "            print(\"Filename: \",test_name)\n",
    "            test_csv = test_zipfile.open(test_name)\n",
    "            test_df = test_csv.read(test_name)\n",
    "            #test_1 = test_csv.open(test_csv)\n",
    "            #test_df = pd.read_csv(io.StringIO(test_1.decode('utf-8')), header=0)\n",
    "            print repr(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10a Journey Data Extract 20Sep15-03Oct15.csv\n",
      "<zipfile.ZipExtFile name='10a Journey Data Extract 20Sep15-03Oct15.csv' mode='r' compress_type=deflate>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zipfile_to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_through_zip():\n",
    "    \n",
    "    test_response = urllib.request.urlopen(\"https://cycling.data.tfl.gov.uk/usage-stats/2015TripDatazip.zip\")\n",
    "    \n",
    "    iter_csv_dict_2015 = { v:k for k,v in csv_dict_2015.items()}\n",
    "\n",
    "    with ZipFile(BytesIO(test_response.read())) as test_zipfile:\n",
    "        \n",
    "        all_dfs = []\n",
    "        for test_csv in test_zipfile.namelist():\n",
    "            print(test_csv)\n",
    "            test1 = test_zipfile.open(test_csv)\n",
    "                print(test1)\n",
    "                #convert each csv to dataframe\n",
    "                #test_dfs = pd.read_csv(io.StringIO(csv.decode('utf-8')), header=0)\n",
    "                #all_dfs.append(test_dfs)\n",
    "        \n",
    "        #print(all_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterate_through_zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10a.JourneyDataExtract20Sep15-03Oct15.csv',\n",
       " '10b.JourneyDataExtract04Oct15-17Oct15.csv',\n",
       " '11a.JourneyDataExtract18Oct15-31Oct15.csv',\n",
       " '11b.JourneyDataExtract01Nov15-14Nov15.csv',\n",
       " '12a.JourneyDataExtract15Nov15-27Nov15.csv',\n",
       " '12b.JourneyDataExtract28Nov15-12Dec15.csv',\n",
       " '13a.JourneyDataExtract13Dec15-24Dec15.csv',\n",
       " '13b.JourneyDataExtract25Dec15-09Jan16.csv',\n",
       " '1a.JourneyDataExtract04Jan15-17Jan15.csv',\n",
       " '1b.JourneyDataExtract18Jan15-31Jan15.csv',\n",
       " '2a.JourneyDataExtract01Feb15-14Feb15.csv',\n",
       " '2b.JourneyDataExtract15Feb15-28Feb15.csv',\n",
       " '3a.JourneyDataExtract01Mar15-15Mar15.csv',\n",
       " '3b.JourneyDataExtract16Mar15-31Mar15.csv',\n",
       " '4a.JourneyDataExtract01Apr15-16Apr15.csv',\n",
       " '4b.JourneyDataExtract 17Apr15-02May15.csv',\n",
       " '5a.JourneyDataExtract03May15-16May15.csv',\n",
       " '5b.JourneyDataExtract17May15-30May15.csv',\n",
       " '6a.JourneyDataExtract31May15-12Jun15.csv',\n",
       " '6b.JourneyDataExtract13Jun15-27Jun15.csv',\n",
       " '7a.JourneyDataExtract28Jun15-11Jul15.csv',\n",
       " '7b.JourneyDataExtract12Jul15-25Jul15.csv',\n",
       " '8a.JourneyDataExtract26Jul15-07Aug15.csv',\n",
       " '8b.JourneyData Extract 08Aug15-22Aug15.csv',\n",
       " '9a.JourneyDataExtract23Aug15-05Sep15.csv',\n",
       " '9b.JourneyDataExtract06Sep15-19Sep15.csv']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_csv_dict_2015 = { v:k for k,v in csv_dict_2015.items()}\n",
    "[iter_csv_dict_2015.get(item,item)  for item in test_zipfile.namelist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dictionary to standardise the names of all csv's\n",
    "csv_dict_2015 = {\"6a.JourneyDataExtract31May15-12Jun15.csv\":'6aJourneyDataExtract31May15-12Jun15.csv',\n",
    "                 \"6b.JourneyDataExtract13Jun15-27Jun15.csv\":'6bJourneyDataExtract13Jun15-27Jun15.csv',\n",
    "                 \"8a.JourneyDataExtract26Jul15-07Aug15.csv\":'8aJourneyDataExtract26Jul15-07Aug15.csv',\n",
    "                 \"8b.JourneyData Extract 08Aug15-22Aug15.csv\":'8bJourneyData Extract 08Aug15-22Aug15.csv',\n",
    "                 \"9a.JourneyDataExtract23Aug15-05Sep15.csv\":'9a-Journey-Data-Extract-23Aug15-05Sep15.csv', \n",
    "                 \"9b.JourneyDataExtract06Sep15-19Sep15.csv\":'9b-Journey-Data-Extract-06Sep15-19Sep15.csv',\n",
    "                 \"10a.JourneyDataExtract20Sep15-03Oct15.csv\":'10a Journey Data Extract 20Sep15-03Oct15.csv',\n",
    "                 \"10b.JourneyDataExtract04Oct15-17Oct15.csv\":'10b Journey Data Extract 04Oct15-17Oct15.csv',\n",
    "                 \"11a.JourneyDataExtract18Oct15-31Oct15.csv\":'11a Journey Data Extract 18Oct15-31Oct15.csv',\n",
    "                 \"11b.JourneyDataExtract01Nov15-14Nov15.csv\":'11b Journey Data Extract 01Nov15-14Nov15.csv',\n",
    "                 \"12a.JourneyDataExtract15Nov15-27Nov15.csv\":'12a Journey Data Extract 15Nov15-27Nov15.csv',\n",
    "                 \"12b.JourneyDataExtract28Nov15-12Dec15.csv\":'12b Journey Data Extract 28Nov15-12Dec15.csv',\n",
    "                 \"13a.JourneyDataExtract13Dec15-24Dec15.csv\":'13a Journey Data Extract 13Dec15-24Dec15.csv',\n",
    "                 \"13b.JourneyDataExtract25Dec15-09Jan16.csv\":'13b Journey Data Extract 25Dec15-09Jan16.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bike_data(year):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#misc stuff\n",
    "                all_dfs.append(test_dfs)\n",
    "                \n",
    "        \n",
    "        print(all_dfs)\n",
    "\n",
    "        for test_csv in test_zipfile.namelist():\n",
    "            \n",
    "            print(\"Old test_csv name: \",test_csv)\n",
    "            iter_csv_dict_2015.get(test_csv,test_csv)\n",
    "            \n",
    "            #write new csv name as dictionary key\n",
    "            \n",
    "            \n",
    "            print(\"Should be this name: \",iter_csv_dict_2015.get(test_csv,test_csv))\n",
    "            print(\"New test_csv name: \",test_csv)\n",
    "#            for line in test_zipfile.open(test_csvs).readlines():\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
